{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvb58I5MpPlB"
   },
   "source": [
    "# Lab 2 - Classification and Fitting with Neural Networks in Tensorflow\n",
    "\n",
    "\n",
    "In this notebook, you will be introduced to tensorflow. We will\n",
    "\n",
    "-  perform function fitting with neural networks (Part A)\n",
    "-  perform classification on handwritten digits using Tensorflow (Part B)\n",
    "\n",
    "Complete the code where appropriate according to the instructions (see comments)\n",
    "\n",
    "Your are free to tweak the hyper-parameters (including number of hidden units, number of hidden layers, learning rate, num of iterations and so on) to improve the performance of the model. \n",
    "\n",
    "Make sure that your final submission is a notebook that can be run from beginning to end\n",
    "\n",
    "For Part A: You should try to get pretty close to the ground truth function where requested. \n",
    "\n",
    "For Part B: The submitted prediction accuracy on testing set, should be > 60%. It is in fact easy to achieve >95% of the accuracy on this dataset with careful tuning of hyper-parameters. **Your grade will depend on the final prediction accuracy**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qnq3LEr0pPlC"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgr0Jg_3pPlD"
   },
   "outputs": [],
   "source": [
    "tf.__version__ # Make sure you have version >2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gzk9NffBpPlE"
   },
   "source": [
    "# Short Experiments with Tensors\n",
    "No Code is necessary in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kq3PHJ2ApPlF"
   },
   "outputs": [],
   "source": [
    "# Let's create a random tensor \n",
    "t = tf.random.uniform([2,3],-1,3)\n",
    "t # t.shape -> (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMS0QToTpPlF"
   },
   "outputs": [],
   "source": [
    "5*(t**2+10) # Tensor arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo16ANQKpPlG"
   },
   "outputs": [],
   "source": [
    "t.numpy() # convert to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSIHd8CgpPlG"
   },
   "source": [
    "# Part A: Function fitting using Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW40VdJMpPlG"
   },
   "source": [
    "## Fit a Simple Linear Function\n",
    "- No need to change anything in this subsection\n",
    "- Read the code and understand what is happening\n",
    "\n",
    "- In this part you will see how to use tensorflow to implement a simple linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moMLZVFApPlH"
   },
   "outputs": [],
   "source": [
    "# No code changes are necessary here but feel free to experiment\n",
    "true_a = 1.13\n",
    "true_b = 2.3\n",
    "datapoints =  1000\n",
    "noise_intensity = 0.1\n",
    "data_x = (np.arange(datapoints) / (datapoints) - .5).astype(np.float32) # Chainer assumes all the cpu computation is done in float32\n",
    "data_y = (data_x * true_a + true_b + np.random.randn(*data_x.shape) * noise_intensity).astype(np.float32)\n",
    "_ = plt.scatter(data_x, data_y, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03_9nBlapPlI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers,Model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(1,input_shape=[1])) # no activation function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llx5CxtLpPlI"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"mse\")\n",
    "# NOTE during your experimentation you can use verbose=1 or 2, but for final result you can use verbose=0\n",
    "history = model.fit(data_x,data_y,epochs=250,verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnLzLPAxpPlI"
   },
   "outputs": [],
   "source": [
    "model.layers # Observe the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPwcNclZpPlJ"
   },
   "outputs": [],
   "source": [
    "model.layers[0].weights # Observe the weights learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb_KOAOxpPlJ"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_x, data_y, c='b')\n",
    "plt.plot(data_x, model.predict(data_x).T[0],c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOm6rJ0LpPlK"
   },
   "source": [
    "## Fit a nonlinear function using Neural Networks \n",
    "\n",
    "- In this part you will write code that fits the dataset below.\n",
    "- The ground truth is a sinusoidal function but there is noise added\n",
    "- you should implement a slightly more complicated model than before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOxaA14mpPlK"
   },
   "outputs": [],
   "source": [
    "# no need to change anything here\n",
    "# this generates the data\n",
    "freq = 10\n",
    "noise_intensity = 0.4\n",
    "data_y2 = ( np.sin(freq*data_x) * true_a + true_b + np.random.randn(*data_x.shape) * noise_intensity).astype(np.float32)\n",
    "_ = plt.scatter(data_x, data_y2, c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXAg9qgv5xxM"
   },
   "source": [
    "- implement the neural network model in the following cell\n",
    "- to do that you can experiment with various methods. You can try to put more than one layers. Experiment with the number of parameters per layer as well. \n",
    "- you will need to use some activation function to introduce nonlinearity in your neural network. \n",
    "- to introduce nonlinearity you can use the parameter activation=\"relu\" in a Dense layer for example. There are other activation functions you can try as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hfj2uzxGpPlL"
   },
   "outputs": [],
   "source": [
    "# TODO Make a nonlinear model to fit the nonlinear function\n",
    "\n",
    "#model = tf.keras.Sequential() \n",
    "#model.add(...)\n",
    "# ....\n",
    "#model.add(...)\n",
    "#model.compile(optimizer=\"Adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f7nkthDpPlL"
   },
   "outputs": [],
   "source": [
    "history = model.fit(data_x,data_y2,epochs=250,verbose=0) # fit your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMr5I_anpPlL"
   },
   "outputs": [],
   "source": [
    "model.layers # Notice how many dense layers we have now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7RrfeCZpPlL"
   },
   "outputs": [],
   "source": [
    "# overlay answer and data\n",
    "# NOTE: your result should be close to the ground truth function (sinusoidal function)\n",
    "plt.scatter(data_x, data_y2, c='b')\n",
    "plt.plot(data_x, model.predict(data_x).T[0],c='r')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGNI_g1SpPlM"
   },
   "outputs": [],
   "source": [
    "# How does your model extrapolate? \n",
    "# -> It's okay if it doesn't extrapolate\n",
    "plt.scatter(data_x, data_y2, c='b')\n",
    "plt.plot(data_x-1, model.predict(data_x-1).T[0],c='r') \n",
    "plt.plot(data_x, model.predict(data_x).T[0],c='r') \n",
    "plt.plot(data_x+1, model.predict(data_x+1).T[0],c='r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrGe48r3pPlM"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL Question \n",
    "# - Create your dataset based on teh function of your choice (logarithmic, root, exponential etc)\n",
    "# - Your dataset for X can be different than a uniform grid, say for example uniform distribution, normal distribution etc\n",
    "# - does your model interpolate well? does it extrapolate well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA6ZwVFnpPlM"
   },
   "source": [
    "# Part B: Classification using Neural Networks\n",
    "\n",
    "In this part we build a model for image classification. \n",
    "We will use the MNIST hand written digit dataset, which is a toy benchmark for image\n",
    "classification models. First load the dataset via TensorFlow API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6z0hsnHpPlM"
   },
   "source": [
    "Here $X_{train},Y_{train}$ denote the training data and $X_{test},Y_{test}$ denote the testing data. We train the model on training set and evaluate its performance on testing set (to evaluate potential under-fitting or over-fitting). As can be seen below, $X_{train}$ contains a lot of examples with $28 \\times 28 $ pixels. $Y_{train}$ contains the corresponding labels (i.e. the $10$ classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbZQ4jATpPlN"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\") # Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HG9m1MbbpPlN"
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qgwdC40pPlN"
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255.0 # Normalize your data\n",
    "X_test  = X_test/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab51xfarpPlO"
   },
   "outputs": [],
   "source": [
    "# Print an image and its label\n",
    "plt.imshow(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vr93nLsCpPlO"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a simple Model to predict the label of a digit with one dense layer\n",
    "#model = tf.keras.Sequential()\n",
    "#model.add(layers.Flatten(input_shape=[28,28]))\n",
    "#model.add(...)\n",
    "#model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
    "#history = model.fit(X_train,Y_train, epochs= ...,validation_data=....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyPfbD6epPlP"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test) # Evaluate your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CUP8g2bpPlP"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a more complicated model with more than one layers\n",
    "# and evaluate your model on the test set\n",
    "# try to improve the performance compared to the previous model\n",
    "\n",
    "# model.evaluate(X_test,Y_test) # Evaluate your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovu8ZRqQpPlP"
   },
   "outputs": [],
   "source": [
    "# Optional question\n",
    "# Identify digits that your model mispredicts, and display them. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 2 - Classification and Fitting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
